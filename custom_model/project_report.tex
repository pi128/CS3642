\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{titlesec}
\usepackage{listings}
\usepackage{xcolor}

\titleformat{\section}{\large\bfseries}{}{}{}
\titleformat{\subsection}{\normalsize\bfseries}{}{}{}

% Code listing style
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    backgroundcolor=\color{gray!10},
    language=Python,
    keywordstyle=\color{blue},
    commentstyle=\color{green},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray}
}

\title{CS3642 Project Report\\[4pt]
\large From Audio to Frets: AI-Driven Guitar Transcription and GUI Integration}
\author{James Widner \quad \texttt{001121770}}
\date{\today}

\begin{document}
\maketitle

\section*{Summary (Executive Overview)}
This project is developing an \textbf{AI system that listens to guitar audio and produces chord classifications with a user-friendly GUI interface}. The current implementation faces significant challenges with both CREPE-based pitch estimation and custom-trained neural networks, requiring substantial improvements in model reliability and accuracy. The system includes a comprehensive GUI application for real-time audio processing, model selection, and results visualization, but the core transcription accuracy remains a work in progress. The project focuses on developing more reliable custom models through improved training data and architecture refinements, while establishing the foundation for connecting AI transcription output to robotic guitar systems through modular design.

\section*{Project Progress Overview}
The project has established foundational components but faces significant accuracy challenges:

\textbf{COMPLETED COMPONENTS:}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{GUI Framework:} Professional user interface with file import, real-time recording, and results display
  \item \textbf{System Architecture:} Modular design with custom model integration and configuration management
  \item \textbf{Audio Processing Pipeline:} scipy-based audio analysis with preprocessing and feature extraction
  \item \textbf{Custom Model Implementation:} Neural network architecture with feature extraction, chord classification, and pitch estimation
  \item \textbf{Training Infrastructure:} Data loading, model training pipeline, and evaluation framework
  \item \textbf{Testing Framework:} Integration and unit testing achieving 83.3\% success rate
\end{itemize}

\textbf{CURRENT CHALLENGES (Work in Progress):}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{CREPE Model Reliability:} Frequent failures in pitch estimation and chord detection
  \item \textbf{Custom Model Accuracy:} Low prediction confidence and inconsistent chord classification
  \item \textbf{Training Data Quality:} Limited datasets leading to poor generalization
  \item \textbf{Model Performance:} Both simple (7-chord) and large (2-class) models show unreliable results
  \item \textbf{Real-time Processing:} Inconsistent performance during live audio analysis
\end{itemize}

\section*{Technical Implementation}

\subsection*{CREPE Model Integration and Challenges}
The project initially integrated CREPE (CNN-based pitch estimation) as the primary transcription method, but encountered significant reliability issues:

\textbf{CREPE Implementation Challenges:}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{Pitch Estimation Failures:} CREPE frequently produces incorrect pitch estimates for guitar audio
  \item \textbf{Chord Detection Issues:} Poor performance on polyphonic guitar recordings with multiple simultaneous notes
  \item \textbf{Latency Problems:} High computational overhead causing GUI responsiveness issues
  \item \textbf{Dependency Conflicts:} Python 3.14 compatibility issues with librosa and related audio processing libraries
  \item \textbf{Generalization Limitations:} CREPE trained on diverse audio but struggles with guitar-specific characteristics
\end{itemize}

\textbf{CREPE Design Process and Limitations:}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{Template Matching Approach:} CREPE uses pre-trained CNN features but lacks guitar-specific training
  \item \textbf{Monophonic Bias:} Designed primarily for single-note pitch estimation, not polyphonic chord recognition
  \item \textbf{Feature Extraction:} Uses mel-spectrograms optimized for speech/music but not guitar harmonics
  \item \textbf{Post-processing Issues:} Limited temporal smoothing for guitar-specific playing patterns
\end{itemize}

\subsection*{Custom Model Development Strategy}
Due to CREPE's limitations, the project focuses on developing reliable custom-trained models:

\textbf{Custom Architecture Design:}
\begin{lstlisting}[language=Python, caption={Custom Model Architecture}]
class CustomGuitarModel(nn.Module):
    def __init__(self, num_chords=7, num_strings=6, num_frets=24):
        super().__init__()
        # Guitar-specific feature extraction
        self.feature_extractor = GuitarFeatureExtractor()
        # Chord classification head
        self.chord_classifier = ChordClassifier(num_chords)
        # Pitch estimation head
        self.pitch_estimator = PitchEstimator(num_strings, num_frets)
\end{lstlisting}

\textbf{Training Data Strategy:}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{Simple Dataset:} 7 major chord samples (A, B, C, D, E, F, G) for initial validation
  \item \textbf{Large Dataset:} SMT Guitar dataset (~500 samples) for broader chord type classification
  \item \textbf{Data Quality Issues:} Current datasets insufficient for reliable model performance
  \item \textbf{Future Data Sources:} GuitarSet (180 professional recordings), IDMT-SMT-CHORDS (7,398 segments)
\end{itemize}

\subsection*{Current Model Performance Analysis}
Both custom models show significant reliability issues requiring substantial improvement:

\textbf{Simple Model (7 Classes) - Current Issues:}
\begin{itemize}[leftmargin=*,itemsep=1pt]
  \item \textbf{Classes:} A, B, C, D, E, F, G major chords
  \item \textbf{Performance:} Inconsistent predictions with low confidence scores
  \item \textbf{Training Data:} Only 7 audio samples - insufficient for reliable learning
  \item \textbf{Confidence Issues:} Often produces unrealistic confidence levels
  \item \textbf{Generalization:} Poor performance on audio not in training set
\end{itemize}

\textbf{Large Model (2 Classes) - Current Issues:}
\begin{itemize}[leftmargin=*,itemsep=1pt]
  \item \textbf{Classes:} Major, Minor chord types only
  \item \textbf{Performance:} Limited to binary classification, cannot identify specific chords
  \item \textbf{Training Data:} SMT Guitar dataset (~500 samples) but limited chord diversity
  \item \textbf{Labeling Problems:} XML-based labels often generic (Major/Minor) rather than specific
  \item \textbf{Accuracy:} Unreliable predictions with frequent misclassifications
\end{itemize}

\textbf{Key Problems Identified:}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{Insufficient Training Data:} Both models trained on inadequate datasets
  \item \textbf{Poor Data Quality:} Labels often incorrect or too generic
  \item \textbf{Architecture Limitations:} Current design may not be optimal for guitar audio
  \item \textbf{Feature Extraction Issues:} Audio preprocessing may not capture guitar-specific characteristics
  \item \textbf{Overfitting:} Models memorize training data rather than learning generalizable patterns
\end{itemize}

\subsection*{GUI Development}
The project includes multiple GUI implementations:

\textbf{Main Features:}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{File Processing:} Audio file import with format support (WAV, MP3, FLAC)
  \item \textbf{Real-time Recording:} Live audio capture with level monitoring
  \item \textbf{Model Selection:} Support for custom and pre-trained models
  \item \textbf{Results Display:} Professional tablature formatting with confidence scores
  \item \textbf{Configuration Management:} Comprehensive settings with preset options
\end{itemize}

\section*{Experimental Results and Analysis}

\subsection*{Current Performance Challenges}
The integration testing revealed significant issues with both CREPE and custom model reliability:

\textbf{CREPE Model Failures:}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{Pitch Estimation Errors:} Frequent incorrect pitch detection on guitar audio
  \item \textbf{Chord Recognition Issues:} Poor performance on polyphonic guitar recordings
  \item \textbf{Processing Latency:} High computational overhead causing GUI freezing
  \item \textbf{Dependency Problems:} Python 3.14 compatibility issues preventing reliable operation
\end{itemize}

\textbf{Custom Model Reliability Issues:}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{Low Confidence Scores:} Models often produce unrealistic confidence levels
  \item \textbf{Inconsistent Predictions:} Same audio input produces different results
  \item \textbf{Poor Generalization:} Models fail on audio not in training set
  \item \textbf{Training Data Limitations:} Insufficient and low-quality training data
\end{itemize}

\subsection*{System Performance Metrics}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{Startup Time:} < 2 seconds for GUI initialization
  \item \textbf{Processing Time:} Variable due to model reliability issues
  \item \textbf{Memory Usage:} < 500MB for full system operation
  \item \textbf{Integration Testing:} 83.3\% success rate (5/6 components passing)
  \item \textbf{Model Accuracy:} Currently unreliable - requires significant improvement
\end{itemize}

\section*{Technical Challenges and Solutions}

\subsection*{Dependency Management}
\textbf{Challenge:} Python 3.14 compatibility issues with audio processing libraries (librosa, pyaudio).

\textbf{Solution:} Implemented graceful degradation using scipy for audio processing, with fallback options and alternative GUI versions for different environments.

\subsection*{Model Integration}
\textbf{Challenge:} Different model architectures and chord class mappings between datasets.

\textbf{Solution:} Created unified interface that handles multiple model types and automatically adapts chord mappings based on loaded model.

\subsection*{Real-time Processing}
\textbf{Challenge:} GUI responsiveness during audio processing.

\textbf{Solution:} Implemented threading for background processing with progress indicators and real-time audio level monitoring.

\section*{Future Research Directions}

\subsection*{Data Enhancement (Priority 1)}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{GuitarSet Dataset:} 180 professional recordings with detailed fret/string annotations
  \item \textbf{IDMT-SMT-CHORDS:} 7,398 chord segments with precise timing information
  \item \textbf{Expanded Classes:} 14 chord types (A-G major + A-G minor)
  \item \textbf{Data Augmentation:} Pitch shifting, time stretching, noise addition
\end{itemize}

\subsection*{Model Improvements (Priority 2)}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{Transfer Learning:} Pre-trained audio models (VGGish, OpenL3)
  \item \textbf{Ensemble Methods:} Multiple model consensus for improved accuracy
  \item \textbf{Multi-task Learning:} Simultaneous chord and tablature prediction
  \item \textbf{Attention Mechanisms:} Focus on relevant audio regions
\end{itemize}

\subsection*{System Enhancements (Priority 3)}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{Advanced Export:} MIDI, PDF, LaTeX, MusicXML output formats
  \item \textbf{Batch Processing:} Multiple file analysis with progress tracking
  \item \textbf{Plugin Architecture:} Extensible model system for future improvements
  \item \textbf{Robotic Integration:} Physical guitar control system development
\end{itemize}

\section*{Research Contributions}

\subsection*{Academic Impact}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{Novel Architecture:} Multi-component neural network specifically designed for guitar transcription
  \item \textbf{Comparative Analysis:} Comprehensive evaluation of different dataset impacts on model performance
  \item \textbf{Integration Framework:} Seamless combination of multiple machine learning approaches
  \item \textbf{User Interface Design:} Musician-friendly transcription tools with professional workflow
\end{itemize}

\subsection*{Practical Applications}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{Music Education:} Automated chord recognition for learning and practice
  \item \textbf{Performance Analysis:} Real-time feedback for musicians during practice
  \item \textbf{Music Production:} Automated transcription for recording sessions and arrangement
  \item \textbf{Accessibility:} Tools for musicians with different skill levels and learning styles
\end{itemize}

\section*{Methodology and Development Environment}

\subsection*{Technical Stack}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{Machine Learning:} PyTorch for neural network implementation and training
  \item \textbf{Audio Processing:} scipy, soundfile for audio I/O and signal processing
  \item \textbf{User Interface:} tkinter for cross-platform GUI development
  \item \textbf{Data Analysis:} NumPy for numerical computation and array processing
  \item \textbf{Visualization:} Matplotlib for data visualization and training analysis
\end{itemize}

\subsection*{Research Methodology}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{Experimental Design:} Systematic model comparison with controlled experiments
  \item \textbf{Cross-validation:} Robust performance evaluation across different datasets
  \item \textbf{Integration Testing:} Comprehensive validation of system components
  \item \textbf{User Testing:} Interface usability evaluation and workflow optimization
\end{itemize}

\section*{Conclusion and Key Insights}

This project has established a comprehensive foundation for AI-driven guitar transcription but faces significant challenges in model reliability and accuracy. The work demonstrates the complexity of automatic music transcription while providing a solid framework for continued development.

\textbf{Current Status - Work in Progress:}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{GUI Framework:} Successfully implemented professional user interface
  \item \textbf{System Architecture:} Modular design established for future improvements
  \item \textbf{CREPE Integration:} Implemented but unreliable for guitar audio
  \item \textbf{Custom Models:} Architecture designed but requires better training data
  \item \textbf{Model Accuracy:} Currently insufficient for practical use
\end{itemize}

\textbf{Key Challenges Identified:}
\begin{enumerate}[leftmargin=*,itemsep=2pt]
  \item \textbf{CREPE Limitations:} Pre-trained model not suitable for guitar-specific transcription
  \item \textbf{Training Data Quality:} Current datasets insufficient for reliable model performance
  \item \textbf{Model Architecture:} May need refinement for guitar audio characteristics
  \item \textbf{Feature Extraction:} Audio preprocessing requires guitar-specific optimization
  \item \textbf{Generalization:} Models fail to perform on unseen audio data
\end{enumerate}

\textbf{Future Development Priorities:}
\begin{itemize}[leftmargin=*,itemsep=2pt]
  \item \textbf{Data Acquisition:} Obtain professional datasets (GuitarSet, IDMT-SMT-CHORDS)
  \item \textbf{Model Redesign:} Develop guitar-specific architecture and training strategies
  \item \textbf{Feature Engineering:} Optimize audio preprocessing for guitar characteristics
  \item \textbf{Validation Framework:} Implement robust testing and evaluation methods
  \item \textbf{Reliability Improvement:} Focus on consistent and accurate predictions
\end{itemize}

The project provides valuable insights into the challenges of automatic music transcription and establishes a foundation for developing more reliable guitar transcription systems through improved data quality and model architecture.

\section*{References}
\begin{enumerate}[leftmargin=*,itemsep=2pt]
  \item McFee et al., ``librosa: Audio and Music Signal Analysis in Python.''
  \item Kim et al., ``CREPE: A Convolutional Representation for Pitch Estimation.''
  \item Hawthorne et al., ``Onsets and Frames: Dual-Objective Piano Transcription.''
  \item Schreiber \& Müller, ``A Single-Step Approach to Chord Transcription.''
  \item Xi et al., ``GuitarSet: A Dataset for Guitar Transcription.''
  \item Défossez et al., ``Demucs: Music Source Separation with CNNs.''
  \item Stoller et al., ``Spleeter: A Fast and State-of-the-Art Music Source Separation Tool.''
  \item Humphrey \& Bello, ``From Chroma to Chords: Robust Chord Recognition.''
  \item Paszke et al., ``PyTorch: An Imperative Style, High-Performance Deep Learning Library.''
  \item Pedregosa et al., ``Scikit-learn: Machine Learning in Python.''
\end{enumerate}

\end{document}